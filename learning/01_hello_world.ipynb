{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import spacy\n",
    "spacy.__version__"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T07:16:20.818623Z",
     "start_time": "2025-07-14T07:16:20.664083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u'I am learning hot to build chatbots')\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ],
   "id": "118e3d9934ed0be1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON\n",
      "am AUX\n",
      "learning VERB\n",
      "hot ADJ\n",
      "to PART\n",
      "build VERB\n",
      "chatbots NOUN\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T07:16:59.659283Z",
     "start_time": "2025-07-14T07:16:59.652004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "doc = nlp('I am going to LONDON next week for a meeting.')\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ],
   "id": "7513d61a0cc22663",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON\n",
      "am AUX\n",
      "going VERB\n",
      "to ADP\n",
      "LONDON PROPN\n",
      "next ADJ\n",
      "week NOUN\n",
      "for ADP\n",
      "a DET\n",
      "meeting NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T07:20:48.981059Z",
     "start_time": "2025-07-14T07:20:48.978028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop)"
   ],
   "id": "e4519cad75e3e044",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I PRON PRP nsubj X True True\n",
      "am be AUX VBP aux xx True True\n",
      "going go VERB VBG ROOT xxxx True False\n",
      "to to ADP IN prep xx True True\n",
      "LONDON LONDON PROPN NNP pobj XXXX True False\n",
      "next next ADJ JJ amod xxxx True True\n",
      "week week NOUN NN npadvmod xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "a a DET DT det x True True\n",
      "meeting meeting NOUN NN pobj xxxx True False\n",
      ". . PUNCT . punct . False False\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T07:26:24.155090Z",
     "start_time": "2025-07-14T07:26:24.151436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "\n",
    "print(porter_stemmer.stem('fastest'))\n",
    "print(snowball_stemmer.stem('fastest'))"
   ],
   "id": "83ac8318050b09ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastest\n",
      "fastest\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T07:32:36.840304Z",
     "start_time": "2025-07-14T07:32:36.833106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Named entity recognition\n",
    "my_string = u\"I flew to New York last Sunday for a conference.\"\n",
    "doc = nlp(my_string)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ],
   "id": "c53260e17ddd93c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York GPE\n",
      "last Sunday DATE\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T07:33:02.196009Z",
     "start_time": "2025-07-14T07:33:02.193651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "print(STOP_WORDS)"
   ],
   "id": "eaaa3559b0b42335",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'front', 'is', 'a', 'here', 'herself', 'at', 'down', 'from', 'none', 'anywhere', 'mostly', 'elsewhere', 'three', 'hundred', 'show', 'ever', 'have', 'throughout', 'name', 'had', \"'d\", 'should', 'thru', 'into', 'they', 'much', 'will', 'done', 'make', 'because', 'toward', 'everywhere', 'alone', 'while', 'due', 'else', 'seemed', 'four', 'two', 'these', 'top', 'their', 'used', 'whom', 'anything', 'say', '‘s', 'several', 'has', 'whereafter', 'if', 'ca', 'are', 'sixty', 'can', 'full', 'there', 'whereas', 'becoming', 'so', 'every', 'how', 'everyone', 'to', 'afterwards', '’ve', 'n’t', 'some', 'both', 'up', 'be', 'on', 'call', 'when', 'own', 're', 'across', '‘m', '’re', 'been', 'still', 'onto', 'others', 'ourselves', 'amongst', 'everything', 'now', 'towards', 'became', 'being', 'whose', 'made', 'yours', 'well', 'n‘t', 'yourselves', 'hereby', 'first', 'otherwise', 'move', 'before', 'yet', 'whoever', 'anyhow', 'what', 'i', 'latterly', \"'ll\", 'or', 'except', 'whither', 'between', 'she', 'would', 'doing', 'must', 'until', 'empty', 'did', 'fifteen', '’d', 'off', 'very', 'almost', 'someone', 'me', '’m', 'same', 'back', 'last', 'somewhere', 'put', 'we', 'under', 'another', 'but', 'beyond', 'since', 'her', 'my', 'neither', 'along', 'it', 'more', 'perhaps', 'themselves', 'beside', 'only', 'out', 'thereby', 'noone', 'those', 'that', 'rather', 'never', 'forty', 'this', 'becomes', 'thus', 'go', 'where', 'thence', 'upon', 'besides', 'enough', 'itself', 'fifty', 'please', 'nobody', 'whole', 'not', 'sometimes', 'by', 'whence', 'them', 'less', 'thereafter', 'yourself', 'regarding', 'seems', 'over', 'something', 'though', 'about', 'somehow', 'give', 'does', 'during', 'few', '‘d', 'together', 'of', 'unless', 'each', 'using', 'an', 'further', 'even', 'quite', 'then', 'such', 'whether', 'wherever', 'nothing', 'most', 'therefore', \"'ve\", 'without', 'serious', 'your', '’ll', 'ours', 'therein', 'however', 'any', 'other', 'with', 'all', 'within', 'anyway', \"'s\", 'the', 'he', 'am', 'around', 'than', 'bottom', 'were', 'may', 'see', 'namely', 'whereupon', 'again', 'nowhere', 'herein', 'meanwhile', 'hence', 'formerly', 'once', 'through', 'eight', 'nevertheless', 'whenever', 'wherein', 'latter', 'part', 'just', 'eleven', 'his', 'nine', 'no', 'hereupon', \"'re\", 'least', 'one', 'for', 'ten', 'really', 'whatever', 'and', 'anyone', 'you', 'mine', 'former', 'often', 'twelve', 'against', 'nor', 'as', 'its', 'seeming', 'amount', \"'m\", 'too', 'get', 'seem', 'why', 'many', 'which', 'in', 'cannot', 'always', 'after', 'might', 'could', '’s', '‘ve', 'third', 'thereupon', 'although', 'do', 'was', 'indeed', 'already', 'take', 'our', 'six', 'who', 'per', 'himself', 'side', 'five', 'hereafter', 'below', 'next', 'become', 'sometime', 'myself', 'whereby', 'moreover', '‘ll', 'among', \"n't\", 'hers', 'beforehand', 'twenty', '‘re', 'either', 'above', 'keep', 'behind', 'various', 'via', 'us', 'also', 'him'}\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T09:28:48.151017Z",
     "start_time": "2025-07-14T09:28:48.143193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dependency parsing\n",
    "from spacy import displacy\n",
    "sentence = \"I am learning how to build chatbots.\"\n",
    "doc = nlp(sentence)\n",
    "# displacy.serve(doc, style=\"dep\", port=8889) # Server already running as its a notebook, therefore we can render only.\n",
    "displacy.render(doc, style=\"dep\")\n"
   ],
   "id": "ecfd1a64ba92ee35",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ccc4259aaa2b4e1da932d4c3d2c09002-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">am</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">learning</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">how</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">build</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">chatbots.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ccc4259aaa2b4e1da932d4c3d2c09002-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ccc4259aaa2b4e1da932d4c3d2c09002-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ccc4259aaa2b4e1da932d4c3d2c09002-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ccc4259aaa2b4e1da932d4c3d2c09002-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ccc4259aaa2b4e1da932d4c3d2c09002-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ccc4259aaa2b4e1da932d4c3d2c09002-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ccc4259aaa2b4e1da932d4c3d2c09002-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ccc4259aaa2b4e1da932d4c3d2c09002-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ccc4259aaa2b4e1da932d4c3d2c09002-0-4\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ccc4259aaa2b4e1da932d4c3d2c09002-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,266.5 L933.0,254.5 917.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ccc4259aaa2b4e1da932d4c3d2c09002-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ccc4259aaa2b4e1da932d4c3d2c09002-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1090.0,266.5 L1098.0,254.5 1082.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T09:32:49.168162Z",
     "start_time": "2025-07-14T09:32:49.162071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# noun chunks example\n",
    "sentence = \"Autonomous cars are moving towards becoming a reality faster than expected.\"\n",
    "\n",
    "# Process the sentence using SpaCy\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Extract and print noun chunks\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(f\"{chunk.text} --> Root: {chunk.root.text}, Dep: {chunk.root.dep_}, Head: {chunk.root.head.text}\")\n"
   ],
   "id": "6aa2491828d5146d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars --> Root: cars, Dep: nsubj, Head: moving\n",
      "a reality --> Root: reality, Dep: attr, Head: becoming\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T09:35:00.618962Z",
     "start_time": "2025-07-14T09:35:00.104037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# finding similarity using word vectors\n",
    "\n",
    "# pick a model that has word vectors\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Example words\n",
    "word1 = nlp(\"king\")\n",
    "word2 = nlp(\"queen\")\n",
    "word3 = nlp(\"apple\")\n",
    "\n",
    "# Print word vectors for each word\n",
    "print(\"Vector for 'king':\", word1.vector)\n",
    "\n",
    "# Compute similarity between words\n",
    "print(f\"Similarity between 'king' and 'queen': {word1.similarity(word2):.3f}\")\n",
    "print(f\"Similarity between 'king' and 'apple': {word1.similarity(word3):.3f}\")\n"
   ],
   "id": "b45101af4ce1a201",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'king': [-6.0644e-01 -5.1205e-01  6.4921e-03 -2.9194e-01 -5.6515e-01 -1.1523e-01\n",
      "  7.7274e-02  3.3561e-01  1.1593e-01  2.3516e+00  5.1773e-02 -5.4229e-01\n",
      " -5.7972e-01  1.3220e-01  2.8430e-01 -7.9592e-02 -2.6762e-01  1.8301e-01\n",
      " -4.1264e-01  2.0459e-01  1.4436e-01 -1.8714e-01 -3.1393e-01  1.7821e-01\n",
      " -1.0997e-01 -2.5584e-01 -1.1149e-01  9.6212e-02 -1.6168e-01  4.0055e-01\n",
      " -2.6115e-01  5.3777e-01 -5.2382e-01  2.7637e-01  7.2191e-01  6.0405e-02\n",
      " -1.7922e-01  1.8020e-01 -1.4381e-01 -1.4795e-01 -8.1394e-02  5.8282e-02\n",
      "  2.2964e-02 -2.6374e-01  1.0704e-01 -4.5425e-01 -1.9964e-01  3.7720e-01\n",
      " -9.7784e-02 -3.1999e-01 -7.8509e-02  6.1502e-01  7.1643e-02 -3.0930e-02\n",
      "  2.1508e-01  2.5280e-01 -3.1643e-01  6.6698e-01  1.9813e-02 -3.2311e-01\n",
      "  2.9266e-02 -4.1403e-02  2.8346e-01 -7.9143e-01  1.3327e-01  7.7231e-02\n",
      " -1.8724e-01 -3.3146e-01 -2.0797e-01 -6.9326e-01 -2.3412e-01 -6.8752e-02\n",
      "  3.8252e-02 -3.2459e-01 -8.3609e-03  1.2945e-01 -2.8316e-01 -5.7546e-01\n",
      "  2.4336e-01  5.6433e-01 -7.1285e-01 -5.4738e-03 -2.3305e-01 -7.1578e-02\n",
      "  4.8301e-01 -3.4312e-01  2.7365e-01 -1.1771e+00 -6.5800e-01 -1.9009e-01\n",
      "  7.4287e-03  3.2977e-01 -1.6647e-01  2.6851e-01  1.1811e-01 -6.2440e-02\n",
      " -4.9987e-02  7.1011e-04 -5.6201e-02 -2.6696e-01  3.1351e-01  4.3955e-01\n",
      " -8.8727e-02 -1.2315e-01  1.8855e-01 -1.0834e+00 -3.3041e-01  5.7325e-01\n",
      " -3.9947e-01  1.4852e-02 -3.6787e-01  3.7842e-01 -2.8962e-01 -7.0543e-02\n",
      " -5.8699e-02  5.3076e-01 -1.2736e-01 -3.5724e-01 -1.5007e-01  1.3823e-02\n",
      " -1.9497e-01 -3.7189e-01  2.6255e-01 -7.6826e-02  8.4217e-02 -5.3640e-01\n",
      "  1.7393e-01 -1.4698e-01 -1.1068e-01  1.7709e-01 -3.9556e-01  1.0433e-01\n",
      "  9.2675e-03 -1.2282e-01 -3.9842e-01 -2.7758e-01 -6.9369e-01  7.0128e-02\n",
      "  8.2794e-02  4.8342e-02 -2.7038e+00 -1.6812e-01  3.1413e-01  2.4313e-02\n",
      " -3.6423e-02  1.9292e-01  4.4872e-01 -4.5427e-01 -3.7271e-01 -9.9532e-01\n",
      " -1.3411e-01 -6.0312e-01  1.6642e-01 -2.4611e-02  6.6891e-01  6.3476e-02\n",
      " -1.1327e+00 -3.3786e-01 -1.2576e-02  3.5344e-01  2.6643e-01 -1.9404e-01\n",
      " -1.9516e-01  6.3670e-01  2.1373e-01 -2.8936e-01 -6.8847e-02 -1.9738e-01\n",
      " -3.5305e-01  1.0219e-01  1.1744e-01  3.7159e-02  4.1041e-01 -1.3766e-02\n",
      " -1.0325e-02  1.0461e-02  3.0697e-02 -3.3016e-01  2.4668e-01 -2.6058e-01\n",
      "  2.8665e-01 -7.8507e-02  6.8945e-03  1.0980e-01 -6.4179e-01  2.4617e-03\n",
      " -2.4693e-01 -1.1188e-02  3.0838e-01  4.5557e-01 -6.2189e-01  1.4873e-01\n",
      "  3.5440e-01  2.8642e-01 -2.4211e-01 -1.2404e-01  2.3326e-01  1.9555e-01\n",
      " -1.2425e-02  1.9920e-01 -1.7935e-01  5.2031e-01 -4.3666e-01  8.6211e-02\n",
      "  1.7282e-01  6.5266e-02  2.8701e-01  6.0238e-01  3.1843e-01 -4.7646e-01\n",
      " -2.1181e-02 -2.7726e-01  4.0253e-01  3.9968e-01  1.8580e-02 -6.2663e-01\n",
      "  3.4149e-01  4.4687e-01 -4.6135e-01  4.4174e-01 -5.7541e-02 -1.9038e-02\n",
      " -2.2626e-01  5.8452e-02 -4.6681e-02 -5.3295e-03 -1.8257e-03  4.8565e-01\n",
      " -4.6144e-01 -4.5877e-01 -1.5891e-01  1.3037e-01 -2.9183e-01  6.9206e-02\n",
      " -4.9825e-02  5.5077e-01  1.4730e-01 -1.9255e-01 -2.3916e-01 -1.9319e-01\n",
      "  1.5643e-01  3.3491e-01 -3.1913e-01  2.0674e-01  6.4556e-02 -2.3195e-01\n",
      "  1.2657e-01 -2.5131e-03  1.1079e-01  3.0436e-01  6.9529e-02  1.1027e-01\n",
      "  2.6285e-01 -2.3103e-01 -2.8933e-01 -5.0675e-02 -8.9796e-02  2.5816e-01\n",
      " -8.0917e-02  3.3160e-01 -3.5930e-01  2.8336e-01  1.4145e-01  2.9012e-01\n",
      "  1.5677e-01  1.3225e-01 -5.0090e-01  2.2110e-01  6.9609e-01 -9.6917e-02\n",
      " -2.4966e-02 -2.9391e-01 -3.1240e-01 -3.8031e-01 -2.0604e-01  1.5959e-01\n",
      " -5.6155e-01  2.9170e-01 -5.0459e-01  6.5684e-02  5.8594e-01  1.3003e-02\n",
      "  6.5874e-01 -4.7811e-01  2.8794e-01  3.5918e-01  4.3347e-01 -4.2480e-01\n",
      "  3.5892e-01 -6.0925e-01 -7.1236e-01  2.9490e-01 -2.1479e-01  2.5658e-01\n",
      " -1.9358e-01  1.1057e+00  2.2862e-01  2.1859e-01 -1.9044e-01 -1.0253e-01]\n",
      "Similarity between 'king' and 'queen': 0.383\n",
      "Similarity between 'king' and 'apple': 0.211\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T09:36:27.656183Z",
     "start_time": "2025-07-14T09:36:27.647409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# word vector\n",
    "sentence1 = nlp(\"The cat sat on the mat.\")\n",
    "sentence2 = nlp(\"A dog is lying on the carpet.\")\n",
    "\n",
    "# Compute sentence similarity\n",
    "print(f\"Similarity between sentences: {sentence1.similarity(sentence2):.3f}\")\n"
   ],
   "id": "1808d794be78cb83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between sentences: 0.828\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T09:36:48.717169Z",
     "start_time": "2025-07-14T09:36:48.705735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tokenization example\n",
    "# Input text\n",
    "text = \"SpaCy is an NLP library. It's designed for processing text efficiently!\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over tokens and print them\n",
    "print(\"Tokens:\")\n",
    "for token in doc:\n",
    "    print(token.text)\n"
   ],
   "id": "f32cdc2dc31233b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n",
      "SpaCy\n",
      "is\n",
      "an\n",
      "NLP\n",
      "library\n",
      ".\n",
      "It\n",
      "'s\n",
      "designed\n",
      "for\n",
      "processing\n",
      "text\n",
      "efficiently\n",
      "!\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T11:18:28.691743Z",
     "start_time": "2025-07-14T11:18:27.465700Z"
    }
   },
   "cell_type": "code",
   "source": "!rasa --version",
   "id": "4e4fb5385e91616",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mayankarora/dib/poc/chatbot-book/.venv/lib/python3.9/site-packages/rasa/core/tracker_store.py:1044: MovedIn20Warning: \u001B[31mDeprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. \u001B[32mTo prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". \u001B[36mSet environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message.\u001B[0m (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\r\n",
      "  Base: DeclarativeMeta = declarative_base()\r\n",
      "Rasa Version      :         3.6.21\r\n",
      "Minimum Compatible Version: 3.6.21\r\n",
      "Rasa SDK Version  :         3.6.2\r\n",
      "Python Version    :         3.9.6\r\n",
      "Operating System  :         macOS-15.1-arm64-arm-64bit\r\n",
      "Python Path       :         /Users/mayankarora/dib/poc/chatbot-book/.venv/bin/python\r\n"
     ]
    }
   ],
   "execution_count": 55
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
